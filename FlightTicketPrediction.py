# -*- coding: utf-8 -*-
"""B20CS045_Bonus.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17AcBWUDfginQMzmWkzjGUvBBAcB8-x_v
"""

# from google.colab import drive
# drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""#Reading Files"""

dfa = pd.read_excel('/content/drive/MyDrive/Bonus_prj.xlsx')
dfa

dfa.Additional_Info.unique()

"""#Exploratory Data Analysis"""

dfa.info()

dfa.isna().sum()

dfa = dfa.dropna()
dfa

dfa["month"] = pd.to_datetime(dfa["Date_of_Journey"], format = "%d/%m/%Y").dt.month

dfa["day"] = pd.to_datetime(dfa.Date_of_Journey, format="%d/%m/%Y").dt.day

dfa["year"] = pd.to_datetime(dfa.Date_of_Journey, format="%d/%m/%Y").dt.year

dfa

dfa.year.unique()

dfa = dfa.drop(['Date_of_Journey' , 'year'] , axis=1)

dfa["Dep_min"] = pd.to_datetime(dfa["Dep_Time"]).dt.minute

dfa["Dep_hour"] = pd.to_datetime(dfa["Dep_Time"]).dt.hour

dfa.drop(["Dep_Time"], axis = 1, inplace = True)

dfa["Arr_hour"] = pd.to_datetime(dfa.Arrival_Time).dt.hour

dfa["Arr_min"] = pd.to_datetime(dfa.Arrival_Time).dt.minute

dfa.drop(["Arrival_Time"], axis = 1, inplace = True)

dfa

li = list(dfa["Duration"])

for i in range(len(li)):
    if len(li[i].split()) < 2:
        if "h" in li[i]:
            li[i] = li[i].strip() + " 0m"
        else:
            li[i] = "0h " + li[i]

la = []
lb = []
for i in li:
    la.append(int(i.split(sep = "h")[0]))
    lb.append(int(i.split(sep = "m")[0].split()[-1]))

dfa["Dur_hours"] = la
dfa["Dur_mins"] = lb

dfa = dfa.drop(["Duration"], axis = 1)

dfa

dfa.dtypes

"""#Visualisations"""

sns.countplot(x='Airline', data=dfa).set_xticklabels(labels=(dfa['Airline'].unique()).tolist() ,rotation=90)

sns.countplot(x='Source', data=dfa).set_xticklabels(labels=(dfa['Source'].unique()).tolist() ,rotation=90)

sns.countplot(x='Destination', data=dfa).set_xticklabels(labels=(dfa['Destination'].unique()).tolist() ,rotation=90)

sns.countplot(x='month', data=dfa)

dfa.Source.unique()

"""#Solving the Routes' problem"""

dfa.Route.unique()

# dfa = dfa.drop(['Route'], axis=1)

dfa

dfa['Route'].value_counts()

dfa['city1']=dfa['Route'].astype(str).str.split('→').str[0]
dfa['city2']=dfa['Route'].astype(str).str.split('→').str[1]
dfa['city3']=dfa['Route'].astype(str).str.split('→').str[2]
dfa['city4']=dfa['Route'].astype(str).str.split('→').str[3]
dfa['city5']=dfa['Route'].astype(str).str.split('→').str[4]

dfa = dfa.drop(['Route'], axis=1)

dfa

dfa.isna().sum()

col = list(dfa.columns)[0:5]
col

col2 = list(dfa.columns)[14:19]
col2

for i in col2:
  col.append(i)

col

"""#Encoding"""

from sklearn.preprocessing import LabelEncoder

for i in col:
  le = LabelEncoder()
  le.fit(dfa[i])
  dfa[i] = le.fit_transform(dfa[i])

dfa

dfa.Additional_Info.unique()

"""#Standardizing"""

dfa.dtypes

dcopy = dfa.copy(deep = True)
dcopy

from sklearn.preprocessing import StandardScaler
scaled_features = dfa.copy()

cols = ['Dur_hours', 'Dur_mins','Dep_hour','Dep_min','Arr_hour','Arr_min']
features = dcopy[cols]
scaler = StandardScaler().fit(features.values)
features = scaler.transform(features.values)

dcopy[cols] = features
dcopy

data = dcopy
data

Y = data.iloc[:,5]
X = data.drop(['Price'], axis=1)
X

X.dtypes

"""#Splitting Data"""

from sklearn.model_selection import train_test_split as tts
X_train, X_test, Y_train, Y_test = tts(X, Y, test_size=0.3)

"""#Importing Models"""

from sklearn.tree import DecisionTreeRegressor as DTR
from sklearn.ensemble import RandomForestRegressor as RFR
from sklearn.neighbors import KNeighborsRegressor as KNR
from sklearn.ensemble import GradientBoostingRegressor as GBR

models = []
models.append(DTR())
models.append(RFR())
models.append(KNR())
models.append(GBR())

from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error

for i in models:
  mdl = i.fit(X_train, Y_train)
  print('Model is : ', i)
  print('Training score: ',mdl.score(X_train,Y_train))
  pred = mdl.predict(X_test)
  print("R2 score: ", (r2_score(Y_test,pred)))
  print("MAE: ", (mean_absolute_error(Y_test,pred)))
  print("MSE: ", (mean_squared_error(Y_test,pred)))
  sns.displot(Y_test-pred)

"""RandomForestRegressor gives best R2 score and MSE.
Also RandomForestRegressor gives best MAE.

#Sequential Feature Selection
"""

import joblib
import sys
sys.modules['sklearn.externals.joblib'] = joblib

!pip install mlxtend

from mlxtend.feature_selection import SequentialFeatureSelector as SFS

mdl = DTR()
sfs = SFS(mdl, forward=True, floating=False, k_features = 8, scoring='neg_mean_squared_error')

sfs = sfs.fit(X, Y)
dic = sfs.subsets_

dic

colsfs = list(dic[8]['feature_names'])
colsfs

df_sfs = pd.DataFrame()
df_sfs
for i in colsfs:
  df_sfs[i] = data[i]
df_sfs['Price'] = Y
df_sfs

X_train2, X_test2, Y_train2, Y_test2 = tts(df_sfs.iloc[:,:-1], df_sfs.iloc[:,-1], test_size=0.3)

for i in models:
  mdl = i.fit(X_train2, Y_train2)
  print('Model is : ', i)
  print('Training score: ',mdl.score(X_train2,Y_train2))
  pred = mdl.predict(X_test2)
  print("R2 score: ", (r2_score(Y_test2,pred)))
  print("MAE: ", (mean_absolute_error(Y_test2,pred)))
  print("MSE: ", (mean_squared_error(Y_test2,pred)))
  sns.displot(Y_test2-pred)

"""Now RandomForestRegressor gives best R2 score, MAE, MSE though training score is a bit reduced.

#Pipeline
"""

from sklearn.pipeline import Pipeline
from sklearn import set_config
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import make_pipeline

pl = Pipeline([ ('scaler', StandardScaler()), ('classifier', RFR()) ])
pl.fit(X_train, Y_train)
pl.score(X_test, Y_test)

numeric_preprocessor = Pipeline([ ("scaler", StandardScaler()) ])
categoric_preprocessor = Pipeline([ ("encoder", LabelEncoder()) ])

preprocessor = ColumnTransformer( [ ("categorical", categoric_preprocessor, col), ("numerical", numeric_preprocessor, cols), ] )

pipe = make_pipeline(preprocessor, RFR())

set_config(display="diagram")
pipe